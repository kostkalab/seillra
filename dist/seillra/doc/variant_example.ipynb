{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6025c4",
   "metadata": {},
   "source": [
    "**Variant Effect for MPRA_eQTL from promoterAI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90917d",
   "metadata": {},
   "source": [
    "Here is an example workflow for doing variant effect predictions. For instructions on downloading data, see manuscript repository: [https://github.com/egilfeather/lowrank-s2f-code](https://github.com/egilfeather/lowrank-s2f-code)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7818267",
   "metadata": {},
   "source": [
    "**Load `seillra model`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d344e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 15:04:02,701 - INFO - Checksum verified for url_a6038b62128b5b01_wts: 28a1a49ca62e4d67a62c170df3751f7255db6eea3923455c119c762dde446308\n",
      "2026-01-23 15:04:02,702 - INFO - Loading state dict from /home/kostka/.cache/seillra/1.4/url_a6038b62128b5b01_wts\n",
      "2026-01-23 15:04:03,211 - INFO - Model weights loaded and set to eval mode.\n",
      "2026-01-23 15:04:03,769 - INFO - Checksum verified for url_9c83e76615711914_wts: ce0baa7e8533604ab579a37ada184832c716e61b285a04b2f97db9367b351df7\n",
      "2026-01-23 15:04:03,770 - INFO - Loading state dict from /home/kostka/.cache/seillra/1.4/url_9c83e76615711914_wts\n",
      "2026-01-23 15:04:03,921 - INFO - Model weights loaded and set to eval mode.\n",
      "2026-01-23 15:04:03,974 - INFO - Checksum verified for url_f6f3b1c27e97399e_wts: ba3e530e53694c66a9573c0a38e0915986b95f19b99a962f357997eadaa33d44\n",
      "2026-01-23 15:04:03,974 - INFO - Loading state dict from /home/kostka/.cache/seillra/1.4/url_f6f3b1c27e97399e_wts\n",
      "2026-01-23 15:04:03,979 - INFO - Model weights loaded and set to eval mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import seillra as sl\n",
    "import pandas as pd\n",
    "\n",
    "rank = 256  # 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048\n",
    "quant = \"CPU\"\n",
    "model = sl.Sei_LLRA(k=rank, projection=True, mode=\"variant\", quant=quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef5719",
   "metadata": {},
   "source": [
    "**Interface with data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb1b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chrom      pos ref alt  strand     gene consequence\n",
      "0  chr1   966179   G   A       1  PLEKHN1        over\n",
      "1  chr1  1000335   C   T      -1     HES4        none\n",
      "2  chr1  6602853   G   A      -1   KLHL21        none\n",
      "3  chr1  6602971   G   C      -1   KLHL21        none\n",
      "4  chr1  6613720   C   G       1    PHF13        none\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./data/MPRA_eQTL.vcf\"\n",
    "df = pd.read_csv(\"./data/MPRA_eQTL.tsv\", sep=\"\\t\", header=0)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0019e8d",
   "metadata": {},
   "source": [
    "**Use `grelu` to turn this into 1-hot encoded data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feb718f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 686/686 [00:08<00:00, 81.43it/s] \n"
     ]
    }
   ],
   "source": [
    "import grelu.sequence.format\n",
    "import torch\n",
    "import tqdm\n",
    "import grelu.io.genome\n",
    "\n",
    "genome = grelu.io.genome.get_genome(\"hg38\")\n",
    "\n",
    "nvars = df.shape[0]\n",
    "refs = torch.empty(nvars, 4, 4096)\n",
    "alts = torch.empty(nvars, 4, 4096)\n",
    "labs = torch.empty(nvars)\n",
    "\n",
    "\n",
    "for index, row in tqdm.tqdm(enumerate(df.itertuples(index=False)), total=nvars):\n",
    "\n",
    "    # - variant position\n",
    "    pos = row.pos - 1\n",
    "\n",
    "    # - chromosome sequence\n",
    "    chrseq = genome[row.chrom]\n",
    "    assert (\n",
    "        str(row.ref).upper() == str(chrseq[pos]).upper()\n",
    "    ), f\"Reference mismatch at chr{row.chrom}:{pos+1}\"\n",
    "\n",
    "    # - alternative sequence\n",
    "    alt_seq = (\n",
    "        str(chrseq[pos - 2048 : pos]) + row.alt + str(chrseq[pos + 1 : pos + 2048])\n",
    "    ).upper()\n",
    "    # - reference sequence\n",
    "    ref_seq = str(chrseq[pos - 2048 : pos + 2048]).upper()\n",
    "    # - one-hot encoding\n",
    "    alt_one_hot = grelu.sequence.format.convert_input_type(alt_seq, \"one_hot\")\n",
    "    alt_one_hot = alt_one_hot.unsqueeze(0)\n",
    "    ref_one_hot = grelu.sequence.format.convert_input_type(ref_seq, \"one_hot\")\n",
    "    ref_one_hot = ref_one_hot.unsqueeze(0)\n",
    "\n",
    "    # - store\n",
    "    refs[index] = ref_one_hot\n",
    "    alts[index] = alt_one_hot\n",
    "\n",
    "    # - label\n",
    "    if row.consequence == \"over\":\n",
    "        labs[index] = 1\n",
    "    else:\n",
    "        labs[index] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c17a80",
   "metadata": {},
   "source": [
    "**Make a `DataLoader`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e69f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class VarD(Dataset):\n",
    "    def __init__(self, refs, alts, labels):\n",
    "        self.refs = refs\n",
    "        self.alts = alts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ref = self.refs[idx]\n",
    "        alt = self.alts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return ref, alt, label\n",
    "\n",
    "\n",
    "var_ds = VarD(refs, alts, labs)\n",
    "var_dl = DataLoader(var_ds, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10065c",
   "metadata": {},
   "source": [
    "**Predict Variant Effect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057da25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting variant data: 100%|██████████| 43/43 [02:23<00:00,  3.33s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "all_sc_ref = []\n",
    "all_sc_alt = []\n",
    "all_labs = []\n",
    "\n",
    "for batch in tqdm.tqdm(var_dl, desc=f\"Predicting variant data\"):\n",
    "    ref, alt, label = batch\n",
    "\n",
    "    # - note that modeel in \"variant\" mode takes care of reverse complementing internally\n",
    "    sc_outputs = model((ref, alt))  # sequence classes for alt and ref\n",
    "\n",
    "    all_sc_ref.append(sc_outputs[0])\n",
    "    all_sc_alt.append(sc_outputs[1])\n",
    "    all_labs.append(label)\n",
    "\n",
    "    # Accumulate by appending to list\n",
    "\n",
    "all_sc_ref = torch.cat([t.detach() for t in all_sc_ref], dim=0).numpy()\n",
    "all_sc_alt = torch.cat([t.detach() for t in all_sc_alt], dim=0).numpy()\n",
    "all_labs = np.concatenate(all_labs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2084214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promoter AUC: 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# - find the promoter index from class annotations\n",
    "promoter_idx = np.where(np.array(model.proj.class_annot) == \"P Promoter\")\n",
    "# - calculate the variant score: overexpression -> more \"promotery\"\n",
    "variant_score = (all_sc_alt[:, promoter_idx] - all_sc_ref[:, promoter_idx]).squeeze()\n",
    "\n",
    "# - find indices wherer df. consequence is \"over\" or \"under\"\n",
    "over_under_idx = df.index[df[\"consequence\"].isin([\"over\", \"under\"])]\n",
    "\n",
    "auc = roc_auc_score(all_labs[over_under_idx], variant_score[over_under_idx])\n",
    "print(f\"Promoter AUC: {auc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seillra_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
